{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1375,"sourceType":"datasetVersion","datasetId":740}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/williamervin7/crimes-in-chicago-cleaning?scriptVersionId=239147379\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:18:15.260869Z","iopub.execute_input":"2025-05-11T16:18:15.261166Z","iopub.status.idle":"2025-05-11T16:18:15.615927Z","shell.execute_reply.started":"2025-05-11T16:18:15.261131Z","shell.execute_reply":"2025-05-11T16:18:15.614916Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Read in the 4 data sets, since the files are big and they're bad lines I inclueded `on_bad_lines='skip',low_memory=False`","metadata":{}},{"cell_type":"code","source":"df1= pd.read_csv('/kaggle/input/crimes-in-chicago/Chicago_Crimes_2001_to_2004.csv', on_bad_lines='skip',low_memory=False)\ndf2= pd.read_csv('/kaggle/input/crimes-in-chicago/Chicago_Crimes_2005_to_2007.csv', on_bad_lines='skip',low_memory=False)\ndf3= pd.read_csv('/kaggle/input/crimes-in-chicago/Chicago_Crimes_2008_to_2011.csv', on_bad_lines='skip',low_memory=False)\ndf4= pd.read_csv('/kaggle/input/crimes-in-chicago/Chicago_Crimes_2012_to_2017.csv', on_bad_lines='skip',low_memory=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:18:15.61742Z","iopub.execute_input":"2025-05-11T16:18:15.617904Z","iopub.status.idle":"2025-05-11T16:19:31.858146Z","shell.execute_reply.started":"2025-05-11T16:18:15.61788Z","shell.execute_reply":"2025-05-11T16:19:31.857496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#combine all 4 tables\ndf = pd.concat([df1, df2, df3, df4], ignore_index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:19:31.85931Z","iopub.execute_input":"2025-05-11T16:19:31.859666Z","iopub.status.idle":"2025-05-11T16:19:34.22521Z","shell.execute_reply.started":"2025-05-11T16:19:31.859639Z","shell.execute_reply":"2025-05-11T16:19:34.224484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#use head to view the data frame\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:19:34.226046Z","iopub.execute_input":"2025-05-11T16:19:34.226321Z","iopub.status.idle":"2025-05-11T16:19:34.275098Z","shell.execute_reply.started":"2025-05-11T16:19:34.226292Z","shell.execute_reply":"2025-05-11T16:19:34.274161Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Comprehensive Exploratory Data Analysis (EDA) Function\nThis function, explore_dataset, performs a thorough exploratory data analysis (EDA) on the provided dataset. It outputs key details such as shape, columns, data types, missing values, and more. It's a great starting point to understand the structure of your data and identify any issues like missing values, empty strings, zeros, or duplicates.","metadata":{}},{"cell_type":"code","source":"# Define a function to perform comprehensive exploratory analysis\ndef explore_dataset(df, name=\"Dataset\"):\n    print(f\"\\n==================== {name} ====================\")\n\n    # Basic informationprint(\"Shape:\", df.shape)\n    print(\"Shape:\", df.shape)\n    print(\"Columns:\", df.columns.tolist())\n    print(\"\\nData Types:\\n\", df.dtypes)\n\n    # Check for missing values (NaNs)print(\"\\nMissing Values:\\n\", df.isnull().sum())\n    print(\"\\nMissing Values:\\n\", df.isnull().sum())\n\n    # Check for empty strings in object-type columnsfor colin df.select_dtypes(include=['object']).columns:\n    # Count empty strings (after stripping whitespace)empty_count= (df[col].str.strip()== '').sum()\n    for col in df.select_dtypes(include='object').columns:\n        empty_count = (df[col].str.strip() == '').sum()\n        print(f\"Empty strings in '{col}': {empty_count}\")\n\n    # Check for zeros in numeric columns numeric_cols= df.select_dtypes(include=[np.number]).columns\n    for col in df.select_dtypes(include='number').columns:\n        zero_count = (df[col] == 0).sum()\n        print(f\"Zeros in '{col}': {zero_count}\")\n\n    # Check for duplicate rowsduplicate_count= df.duplicated().sum()\n    duplicate_count = df.duplicated().sum()\n    print(\"\\nDuplicate rows:\", duplicate_count)\n\n    # Unique value counts for each columnprint(\"\\nUnique value counts:\")\n    print(\"\\nUnique value counts:\")\n    for col in df.columns:\n        print(f\"{col}: {df[col].nunique()}\")\n\n    print(\"===============================================\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:19:34.277696Z","iopub.execute_input":"2025-05-11T16:19:34.278156Z","iopub.status.idle":"2025-05-11T16:19:34.28458Z","shell.execute_reply.started":"2025-05-11T16:19:34.278134Z","shell.execute_reply":"2025-05-11T16:19:34.283737Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# call explore funciton\nexplore_dataset(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:19:34.285322Z","iopub.execute_input":"2025-05-11T16:19:34.285648Z","iopub.status.idle":"2025-05-11T16:21:20.830301Z","shell.execute_reply.started":"2025-05-11T16:19:34.285619Z","shell.execute_reply":"2025-05-11T16:21:20.829371Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# get rid of the Duplicate rows: 1770469\ndf.drop_duplicates(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:21:20.831688Z","iopub.execute_input":"2025-05-11T16:21:20.831961Z","iopub.status.idle":"2025-05-11T16:21:58.339198Z","shell.execute_reply.started":"2025-05-11T16:21:20.831937Z","shell.execute_reply":"2025-05-11T16:21:58.338288Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# get rid of the X Coordinate', 'Y Coordinate', 'Updated On' col\ndf.drop(['X Coordinate', 'Y Coordinate', 'Updated On', 'Unnamed: 0','Case Number','Block'], axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:21:58.340215Z","iopub.execute_input":"2025-05-11T16:21:58.340854Z","iopub.status.idle":"2025-05-11T16:21:59.944648Z","shell.execute_reply.started":"2025-05-11T16:21:58.34083Z","shell.execute_reply":"2025-05-11T16:21:59.943659Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#convert col to proper types\ndf['Date'] = pd.to_datetime(df['Date'], errors='coerce')\ndf['Year'] = df['Year'].astype('int16')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:21:59.945543Z","iopub.execute_input":"2025-05-11T16:21:59.945751Z","iopub.status.idle":"2025-05-11T16:29:35.932294Z","shell.execute_reply.started":"2025-05-11T16:21:59.945734Z","shell.execute_reply":"2025-05-11T16:29:35.931402Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Categorizing Crimes by Police Watch Shifts\nTo better understand when crimes are occurring, we categorized each incident into one of the Chicago Police Department’s three watch shifts based on the hour the crime occurred:\n\n* 1st Watch (Afternoon–Evening): 2:00 PM to 12:00 AM\n\n* 2nd Watch (Overnight): 10:00 PM to 8:00 AM\n\n* 3rd Watch (Morning–Afternoon): 6:00 AM to 4:00 PM\n\nWe used the Date column to extract the hour of each crime and applied np.select() to assign the appropriate watch shift. This will allow us to analyze crime patterns by shift and potentially advise where increased police presence could have the greatest impact.","metadata":{}},{"cell_type":"code","source":"watch_catagories = ['1st','2nd','3rd']\n\nconditions = [\n    (df['Date'].dt.hour >= 14) & (df['Date'].dt.hour < 24),  # 1st Watch: 2 PM to 12 AM\n    ((df['Date'].dt.hour >= 22) | (df['Date'].dt.hour < 8)), # 2nd Watch: 10 PM to 8 AM (overnight)\n    (df['Date'].dt.hour >= 6) & (df['Date'].dt.hour < 16),   # 3rd Watch: 6 AM to 4 PM\n]\n\ndf['Watch'] = np.select(conditions, watch_catagories, default='Error')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:32:18.336797Z","iopub.execute_input":"2025-05-11T16:32:18.337588Z","iopub.status.idle":"2025-05-11T16:32:22.185357Z","shell.execute_reply.started":"2025-05-11T16:32:18.337549Z","shell.execute_reply":"2025-05-11T16:32:22.184478Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop rows with missing Latitude, Longitude,  Location, Location Description and District\ndf = df.dropna(subset=['Latitude', 'Longitude', 'Location', 'Location Description', 'District'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:34:58.72178Z","iopub.execute_input":"2025-05-11T16:34:58.72207Z","iopub.status.idle":"2025-05-11T16:35:02.828153Z","shell.execute_reply.started":"2025-05-11T16:34:58.72205Z","shell.execute_reply":"2025-05-11T16:35:02.827284Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Optimizing Memory Usage by Converting Data Types\nTo save memory, we convert specific columns to the category data type. This is especially useful for columns that have a limited number of unique values. Additionally, we convert the Latitude column to float to ensure it's in the correct data type for numerical analysis.","metadata":{}},{"cell_type":"code","source":"#change 'FBI Code', 'Primary Type', 'Description', 'Location Description','Beat', 'District','Ward','Community Area' and 'Watch' to type category to save memory\ncols_to_convert = ['FBI Code', 'Primary Type', 'Description', 'Location Description','Beat', 'District','Ward','Community Area','Watch']\ndf[cols_to_convert] = df[cols_to_convert].astype('category')\n\n#change 'Latitude to type float'\ndf['Latitude'] = df['Latitude'].astype('float')\ndf.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:35:58.89799Z","iopub.execute_input":"2025-05-11T16:35:58.898306Z","iopub.status.idle":"2025-05-11T16:35:59.862456Z","shell.execute_reply.started":"2025-05-11T16:35:58.898284Z","shell.execute_reply":"2025-05-11T16:35:59.861761Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Mapping FBI Codes to Descriptions\nWe created a dictionary to translate FBI codes into readable offense descriptions. This mapping was applied to create a new FBI Description column, making the data easier to interpret and analyze. The new column was also converted to the category data type for efficiency.","metadata":{}},{"cell_type":"code","source":"#create a dictionary for the FBI code\nfbi_code_dict = {\n    \"01A\": \"Murder and Non-Negligent Manslaughter\",\n    \"01B\": \"Negligent Manslaughter\",\n    \"02\": \"Forcible Rape\",\n    \"03\": \"Robbery\",\n    \"04A\": \"Aggravated Assault\",\n    \"04B\": \"Simple Assault\",\n    \"05\": \"Burglary\",\n    \"06\": \"Larceny/Theft\",\n    \"07\": \"Motor Vehicle Theft\",\n    \"08A\": \"Other Assaults\",\n    \"08B\": \"Assault (Simple)\",\n    \"09\": \"Arson\",\n    \"10\": \"Forgery and Counterfeiting\",\n    \"11\": \"Fraud\",\n    \"12\": \"Embezzlement\",\n    \"13\": \"Stolen Property\",\n    \"14\": \"Vandalism\",\n    \"15\": \"Weapons Violations\",\n    \"16\": \"Prostitution and Commercialized Vice\",\n    \"17\": \"Sex Offenses (Except Rape and Prostitution)\",\n    \"18\": \"Drug Abuse Violations\",\n    \"19\": \"Gambling\",\n    \"20\": \"Offenses Against Family and Children\",\n    \"22\": \"Liquor Law Violations\",\n    \"24\": \"Disorderly Conduct\",\n    \"26\": \"All Other Offenses\"\n}\n#map the dicitonay to create FBI description col of type category\ndf['FBI Description'] = df['FBI Code'].map(fbi_code_dict).astype('category')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:36:07.128035Z","iopub.execute_input":"2025-05-11T16:36:07.128364Z","iopub.status.idle":"2025-05-11T16:36:07.143203Z","shell.execute_reply.started":"2025-05-11T16:36:07.128339Z","shell.execute_reply":"2025-05-11T16:36:07.1423Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Extracting and Formatting Month Information\nWe extracted the month from the Date column and converted both Year and Month to categorical types for optimized analysis. A mapping was applied to replace numeric month values with their corresponding month names to improve readability in visualizations and summaries.","metadata":{}},{"cell_type":"code","source":"#Extract Month from the Date col and make both year and month type category\ndf['Year']= df['Year'].astype('category')\ndf['Month'] = df['Date'].dt.month.astype('category')\n\n#create a replace map for the month \nreplace_map = {\n    1: 'January',\n    2: 'February',\n    3: 'March',\n    4: 'April',\n    5: 'May',\n    6: 'June',\n    7: 'July',\n    8: 'August',\n    9: 'September',\n    10: 'October',\n    11: 'November',\n    12: 'December'\n}\n\n# use the replace mape on the month col\ndf['Month'] = df['Month'].cat.rename_categories(replace_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:36:23.366354Z","iopub.execute_input":"2025-05-11T16:36:23.366675Z","iopub.status.idle":"2025-05-11T16:36:23.694207Z","shell.execute_reply.started":"2025-05-11T16:36:23.366651Z","shell.execute_reply":"2025-05-11T16:36:23.693305Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Saving the Cleaned Data\nAfter performing the necessary cleaning and transformations on the dataset, we save the cleaned DataFrame to a CSV file called crimes_filtered.csv. This file can be used for further analysis in the EDA notebook.","metadata":{}},{"cell_type":"code","source":"df.to_csv('crimes_filtered.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:36:44.229355Z","iopub.execute_input":"2025-05-11T16:36:44.229651Z","iopub.status.idle":"2025-05-11T16:38:07.943335Z","shell.execute_reply.started":"2025-05-11T16:36:44.229631Z","shell.execute_reply":"2025-05-11T16:38:07.942673Z"}},"outputs":[],"execution_count":null}]}